{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook was created and run in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "h4eO3FHY_JQ_",
    "outputId": "f6108166-da59-42ac-8ed9-3bbc7306c6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 17.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 21.7MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 48.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=5bbd6025c45aa5828544a0cfd94ec5154f41d39e32fefd50055255288d5a6a69\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2zvcZSBi_OXl",
    "outputId": "538cf7f8-d2ed-4074-c0d7-3684f12821be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import tokenizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "WqF6yypNR0U7",
    "outputId": "621dc2e2-b1c3-464b-8437-ac80de56e168"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.79.241.82:8470\n",
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "# TPU detection.\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "\n",
    "if tpu:\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "  AUTO = tf.data.experimental.AUTOTUNE\n",
    "else:\n",
    "# Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "  strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvC48VigYpF_"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://www.dropbox.com/s/w6s6hszo1amf53q/train.csv?dl=1\")\n",
    "test = pd.read_csv(\"https://www.dropbox.com/s/ett5vs1tz6xl0w0/test.csv?dl=1\")\n",
    "sample_sub = pd.read_csv(\"https://www.dropbox.com/s/8da3kbzcseumd2p/sample_submission.csv?dl=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_S6y5D5I6TT"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Z6NrOCOgChGw",
    "outputId": "4b34d8cb-afc7-4d54-cff6-4d23414e4dea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  ... sentiment\n",
       "0  cb774db0d1  ...   neutral\n",
       "1  549e992a42  ...  negative\n",
       "2  088c60f138  ...  negative\n",
       "3  9642c003ef  ...  negative\n",
       "4  358bd9e861  ...  negative\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "UPW_4tWC-1AH",
    "outputId": "23dee78f-b64b-4671-94b8-93a3258b3275"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xjnCNLy-Ggk"
   },
   "outputs": [],
   "source": [
    "#print(train.dtypes)\n",
    "train['textID'] = train['textID'].apply(str)\n",
    "train['text'] = train['text'].apply(str)\n",
    "train['selected_text'] = train['selected_text'].apply(str)\n",
    "train['sentiment'] = train['sentiment'].apply(str)\n",
    "\n",
    "test['textID'] = test['textID'].apply(str)\n",
    "test['text'] = test['text'].apply(str)\n",
    "test['sentiment'] = test['sentiment'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "W2olwS_QCsME",
    "outputId": "5a5f6713-6b0e-4fee-becc-872707449854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what interview! leave me alone\n",
      "leave me alone\n"
     ]
    }
   ],
   "source": [
    "ex = train.loc[3,:]\n",
    "context = ex.text\n",
    "answer = ex.selected_text\n",
    "print(context)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "e6cPjG_Ph8wW",
    "outputId": "9d41e902-2543-4b3d-bfaf-79b585bcea71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Download RoBERTa vocabulary file from my Gdrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXYBtxj6V64B"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  shutil.copytree(r'/content/gdrive/My Drive/Colab_data/tf-roberta/', r'tf-roberta')\n",
    "except FileExistsError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "P3L2PcgFBTKQ",
    "outputId": "a158e528-9646-4fac-c662-b6d237dccb93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     11118\n",
       "positive     8582\n",
       "negative     7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "1WwUwJrzBaYB",
    "outputId": "af0091bc-ca96-41d8-b3bd-c9d9b4462a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10005\n",
       "1        171\n",
       "2        116\n",
       "3         66\n",
       "27        57\n",
       "       ...  \n",
       "91         1\n",
       "59         1\n",
       "106        1\n",
       "90         1\n",
       "99         1\n",
       "Length: 98, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train.sentiment == 'neutral',['text', 'selected_text']].apply(lambda row: len(row['text'].strip())-\n",
    "                                                                        len(row['selected_text'].strip()), axis=1 ).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUvYpydBCyHd"
   },
   "outputs": [],
   "source": [
    "ROBERTA_PATH = './tf-roberta/'\n",
    "# Intialize the RoBERTa base tokenizer\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(vocab_file = ROBERTA_PATH+'vocab-roberta-base.json', \n",
    "                                             merges_file = ROBERTA_PATH+'merges-roberta-base.txt',\n",
    "                                            lowercase = True,add_prefix_space=True)\n",
    "\n",
    "def preprocess_input_data_roberta(question, context, answer, tokenizer, max_len):\n",
    "    \n",
    "# Tokenize and encode the question (sentiment) and the context (tweet) with special tokens\n",
    "    context = \" \" + \" \".join(context.split()) # This is done because some tweets start with double spaces, the tokenization then gets messed up\n",
    "    answer = \" \" + \" \".join(answer.split())\n",
    "    enc_question = tokenizer.encode(question)\n",
    "    enc_context = tokenizer.encode(context)\n",
    "    input_ids = [0] + enc_question.ids + [2,2] +   enc_context.ids + [2]\n",
    "    input_tokens = enc_question.tokens + enc_context.tokens\n",
    "    token_type_ids = [0]* len(input_ids) # not relevant for RoBERTa\n",
    "    attention_mask = [1]* len(input_ids)\n",
    "    \n",
    "    offsets_question = enc_question.offsets\n",
    "    offsets_context = enc_context.offsets\n",
    "    offsets = [(0,0)] + offsets_question + [(0,0)]*2 + offsets_context +[(0,0)]\n",
    "    \n",
    "    target_char_start  = context.find(answer)\n",
    "    target_char_end = target_char_start + len(answer) - 1\n",
    "    char_targets = [0]*len(context)\n",
    "    for i in range(target_char_start,target_char_end+1):\n",
    "        char_targets[i] = 1\n",
    "    targets_index_context = []    \n",
    "    for ind, (i,j) in enumerate(offsets_context):\n",
    "        if sum(char_targets[i:j]) > 0:\n",
    "            targets_index_context.append(ind) \n",
    "           \n",
    "    target_start_ind = targets_index_context[0] + 4 \n",
    "    target_end_ind   = targets_index_context[-1] + 4\n",
    "    \n",
    "\n",
    "        # padding -- pad the vectors if their lengths exceed max_len\n",
    "    pad_len = max_len - len(token_type_ids)\n",
    "    if(pad_len> 0):\n",
    "        token_type_ids = token_type_ids + [0]*pad_len\n",
    "        input_ids = input_ids + [1]*pad_len    # [1] is the <pad> token in RoBERTa\n",
    "        attention_mask = attention_mask + [0]*pad_len\n",
    "        offsets = offsets + [(0,0)]*pad_len    \n",
    "\n",
    "        \n",
    "    output_dict = {'token_type_ids': token_type_ids,\n",
    "                  'input_ids': input_ids,\n",
    "                  'token_type_ids': token_type_ids,\n",
    "                  'target_start': target_start_ind,\n",
    "                  'target_end': target_end_ind,\n",
    "                  'input_tokens': input_tokens,\n",
    "                   'offsets': offsets,\n",
    "                   'attention_mask': attention_mask,\n",
    "                   'sentiment': question,\n",
    "                   'context': context,\n",
    "                   'answer': answer\n",
    "                  }\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "xmwBQmYqC1nS",
    "outputId": "29b0436d-525b-490c-a6f9-54e566b07e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:negative\n",
      "Tweet: what interview! leave me alone\n",
      "Selected text: leave me alone\n",
      "Input tokens: ['Ġnegative', 'Ġwhat', 'Ġinterview', '!', 'Ġleave', 'Ġme', 'Ġalone']\n",
      "Token type ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input_ids: [0, 2430, 2, 2, 99, 1194, 328, 989, 162, 1937, 2, 1, 1, 1, 1]\n",
      "Target start index: 7, Target end index: 9\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "offsets: [(0, 0), (0, 8), (0, 0), (0, 0), (0, 5), (5, 15), (15, 16), (16, 22), (22, 25), (25, 31), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "data_example = preprocess_input_data_roberta(train.sentiment[3], train.text[3], train.selected_text[3], tokenizer, max_len = 15)\n",
    "print('Sentiment:{}'.format(data_example['sentiment']))\n",
    "print('Tweet:{}'.format(data_example['context']))\n",
    "print('Selected text:{}'.format(data_example['answer']))\n",
    "print('Input tokens: {}'.format(data_example['input_tokens']))\n",
    "print('Token type ids: {}'.format(data_example['token_type_ids']))\n",
    "print('Input_ids: {}'.format(data_example['input_ids']))\n",
    "print('Target start index: {}, Target end index: {}'.format(data_example['target_start'], data_example['target_end']))\n",
    "print('Attention mask: {}'.format(data_example['attention_mask']))\n",
    "print('offsets: {}'.format(data_example['offsets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdcVPw_qC2x1"
   },
   "outputs": [],
   "source": [
    "# Tokenize and encode the training set\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "input_ids = np.ones((train.shape[0],max_len), dtype = np.int32)\n",
    "token_type_ids = np.zeros((train.shape[0],max_len), dtype = np.int32)\n",
    "attention_mask = np.zeros((train.shape[0],max_len), dtype = np.int32)\n",
    "start_ids = np.zeros((train.shape[0],max_len), dtype = np.int32)\n",
    "end_ids = np.zeros((train.shape[0],max_len), dtype = np.int32)\n",
    "\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    question = train.sentiment[i]\n",
    "    context= train.text[i]\n",
    "    answer = train.selected_text[i]\n",
    "    processed_data = preprocess_input_data_roberta(question, context, answer, tokenizer, max_len = max_len)\n",
    "    input_ids[i,:] = processed_data['input_ids']\n",
    "    token_type_ids[i,:] = processed_data['token_type_ids']\n",
    "    attention_mask[i,:] = processed_data['attention_mask']\n",
    "    start_ids[i,:] = to_categorical(processed_data['target_start'], num_classes = max_len)\n",
    "    end_ids[i,:] = to_categorical(processed_data['target_end'], num_classes = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c88PazmAZab5"
   },
   "outputs": [],
   "source": [
    "# Tokenize and encode the test set\n",
    "def preprocess_test_data_roberta(question, context, tokenizer, max_len):\n",
    "    \n",
    "# Tokenize and encode the question (sentiment) and the context (tweet) with special tokens\n",
    "    context = \" \" + \" \".join(context.split())\n",
    "    enc_question = tokenizer.encode(question)\n",
    "    enc_context = tokenizer.encode(context)\n",
    "    input_ids = [0] + enc_question.ids + [2,2] +   enc_context.ids + [2]\n",
    "    input_tokens = enc_question.tokens + enc_context.tokens\n",
    "    attention_mask = [1]* len(input_ids)\n",
    "        \n",
    "    # padding -- pad the vectors if their lengths exceed max_len, else truncate at max_len\n",
    "    pad_len = max_len - len(input_ids)\n",
    "    if(pad_len> 0):\n",
    "        input_ids = input_ids + [1]*pad_len\n",
    "        attention_mask = attention_mask + [0]*pad_len\n",
    "\n",
    "    \n",
    "    output_dict = {'input_ids': input_ids,\n",
    "                  'input_tokens': input_tokens,\n",
    "                   'attention_mask': attention_mask,\n",
    "                   'sentiment': question,\n",
    "                   'context': context,\n",
    "                  }\n",
    "    return output_dict\n",
    "\n",
    "input_ids_test = np.ones((test.shape[0],max_len), dtype = np.int32)\n",
    "token_type_ids_test = np.zeros((test.shape[0],max_len), dtype = np.int32)\n",
    "attention_mask_test = np.zeros((test.shape[0],max_len), dtype = np.int32)\n",
    "\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    question = test.sentiment[i]\n",
    "    context= test.text[i]\n",
    "    processed_data_test = preprocess_test_data_roberta(question, context, tokenizer, max_len = max_len)\n",
    "    input_ids_test[i,:] = processed_data_test['input_ids']\n",
    "    attention_mask_test[i,:] = processed_data_test['attention_mask']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV8mDgAkV_Ut"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model():\n",
    "    ids = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    \n",
    "    config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH+'config-roberta-base.json', output_hidden_states=True)  \n",
    "    roberta_tf = transformers.TFRobertaModel.from_pretrained('roberta-base', config=config)\n",
    "    x = roberta_tf({'input_ids': ids, 'token_type_ids': tok, 'attention_mask': att})[0]\n",
    "\n",
    " # Refer to https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/default/15812785.pdf   \n",
    "\n",
    "\n",
    "#    print(x.shape)\n",
    "    \n",
    "    h1 = tf.keras.layers.Dropout(0.2)(x) \n",
    "    h1 = tf.keras.layers.Dense(1)(h1)\n",
    "    h1 = tf.keras.layers.Flatten()(h1)\n",
    "    h1 = tf.keras.layers.Activation('softmax', name='start_token_id')(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Dropout(0.2)(x) \n",
    "    h2 = tf.keras.layers.Dense(1)(h2)\n",
    "    h2 = tf.keras.layers.Flatten()(h2)\n",
    "    h2 = tf.keras.layers.Activation('softmax', name='end_token_id')(h2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[h1,h2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer = optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644,
     "referenced_widgets": [
      "448410893da446ef8ad741500514f290",
      "985851302cc743319666020683560deb",
      "ed3da6ca14784961aef8ec04fc65d432",
      "ab6b9590599542dab5acb99bf89f78f1",
      "9f221775e79f48138f76eb0144c94b70",
      "9094538dac1d44ce9bf2a93cb5754c33",
      "5b657f4a11d04d2a8685c5215b1e73b3",
      "c05b677ca1c94b88bf7658877b469394"
     ]
    },
    "colab_type": "code",
    "id": "b96PCNJOTMGS",
    "outputId": "99962fa1-2a60-43c5-e088-9a0124221964"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448410893da446ef8ad741500514f290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode ((None, 128, 768), ( 124645632   input_3[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 128, 768)     0           tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 128, 768)     0           tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 1)       769         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1)       769         dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_token_id (Activation)     (None, 128)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "end_token_id (Activation)       (None, 128)          0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 124,647,170\n",
      "Trainable params: 124,647,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egaf5Zy-C39Y"
   },
   "outputs": [],
   "source": [
    "#    config = transformers.BertConfig()\n",
    "\n",
    "def build_model_CNN():\n",
    "    ids = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((max_len,), dtype=tf.int32) \n",
    "\n",
    "    config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH+'config-roberta-base.json', output_hidden_states=True)  \n",
    "    roberta_tf = transformers.TFRobertaModel.from_pretrained('roberta-base', config=config)\n",
    "    x = roberta_tf({'input_ids': ids, 'token_type_ids': tok, 'attention_mask': att})[0]\n",
    " \n",
    "\n",
    "#    print(x.shape)\n",
    "    h1 = tf.keras.layers.Dropout(0.1)(x) \n",
    "    h1 = tf.keras.layers.Conv1D(128, 2,padding='same')(h1)\n",
    "    h1 = tf.keras.layers.BatchNormalization()(h1)\n",
    "    h1 = tf.keras.layers.ReLU()(h1)\n",
    "    h1 = tf.keras.layers.Dense(1)(h1)\n",
    "#    print(h1.shape)\n",
    "    h1 = tf.keras.layers.Flatten()(h1)\n",
    "#    print(h1.shape)\n",
    "    h1 = tf.keras.layers.Activation('softmax', name='start_token_id')(h1)\n",
    "#    print(h1.shape)\n",
    "\n",
    "    h2 = tf.keras.layers.Dropout(0.1)(x) \n",
    "    h2 = tf.keras.layers.Conv1D(128, 2,padding='same')(h2)\n",
    "    h2 = tf.keras.layers.BatchNormalization()(h2)\n",
    "    h2 = tf.keras.layers.ReLU()(h2)\n",
    "    h2 = tf.keras.layers.Dense(1)(h2)\n",
    "    h2 = tf.keras.layers.Flatten()(h2)\n",
    "    h2 = tf.keras.layers.Activation('softmax', name='end_token_id')(h2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[h1,h2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer = optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfJws69G1R1W"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_CNN(num_filters=3,filter_sizes = (3,5)):\n",
    "    ids = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n",
    "    \n",
    "    hidden_dims = 128\n",
    "    \n",
    "    config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH+'config-roberta-base.json')  \n",
    "    roberta_tf = transformers.TFRobertaModel.from_pretrained('roberta-base', config=config)\n",
    "    x = roberta_tf({'input_ids': ids, 'token_type_ids': tok, 'attention_mask': att})[0]\n",
    "\n",
    "#    print(x.shape)\n",
    "    h1 = tf.keras.layers.Dropout(0.1)(x) \n",
    "        # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = tf.keras.layers.Conv1D(filters=num_filters,\n",
    "                             kernel_size=sz,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1)(h1)\n",
    "        conv = tf.keras.layers.MaxPooling1D(pool_size=2)(conv)\n",
    "        conv = tf.keras.layers.Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    h1 = tf.keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "    h1 = tf.keras.layers.Dropout(0.1)(h1)\n",
    "    h1 = tf.keras.layers.Dense(hidden_dims)(h1)\n",
    "    h1 = tf.keras.layers.Flatten()(h1)\n",
    "    h1 = tf.keras.layers.Activation('softmax', name='start_token_id')(h1)\n",
    "\n",
    "\n",
    "\n",
    "    h2 = tf.keras.layers.Dropout(0.1)(x) \n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = tf.keras.layers.Conv1D(filters=num_filters,\n",
    "                             kernel_size=sz,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1)(h2)\n",
    "        conv = tf.keras.layers.MaxPooling1D(pool_size=2)(conv)\n",
    "        conv = tf.keras.layers.Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    h2 = tf.keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "    h2 = tf.keras.layers.Dropout(0.1)(h2)\n",
    "    h2 = tf.keras.layers.Dense(hidden_dims)(h2)\n",
    "    h2 = tf.keras.layers.Flatten()(h2)\n",
    "    h2 = tf.keras.layers.Activation('softmax', name='end_token_id')(h2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[h1,h2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= 3e-5)\n",
    "    model.compile(optimizer = optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "jDXwNEQFzPHv",
    "outputId": "8fda4783-51cb-4c9f-d94e-ae3b6c1e5077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model_1 (TFRobertaMo ((None, 128, 768), ( 124645632   input_6[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 128, 768)     0           tf_roberta_model_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 128, 768)     0           tf_roberta_model_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 128, 128)     196736      dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 128, 128)     196736      dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128)     512         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128)     512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 128, 128)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128, 1)       129         re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128, 1)       129         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_token_id (Activation)     (None, 128)          0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "end_token_id (Activation)       (None, 128)          0           flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 125,040,386\n",
      "Trainable params: 125,039,874\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEiCj8OWDDGz"
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3L_JEtYlSlo"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    return LEARNING_RATE * 0.2**epoch\n",
    "\n",
    "\n",
    "def train_model(input_ids, attention_mask, token_type_ids, input_ids_test,attention_mask_test,token_type_ids_test,kfold_n_splits = 5, epochs=3):\n",
    "  jaccard_scores = []\n",
    "  oof_start = np.zeros((input_ids.shape[0],max_len))\n",
    "  oof_end = np.zeros((input_ids.shape[0],max_len))\n",
    "  preds_start = np.zeros((input_ids_test.shape[0],max_len))\n",
    "  preds_end = np.zeros((input_ids_test.shape[0],max_len))\n",
    "\n",
    "  \n",
    "\n",
    "  skf = StratifiedKFold(n_splits=kfold_n_splits,shuffle=True,random_state=12345)\n",
    "  for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
    "    K.clear_session()\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    \n",
    "    print('#'*25)\n",
    "    print('### FOLD {}'.format(fold+1))\n",
    "    print('#'*25)\n",
    "    X_train = (\n",
    "        tf.data.Dataset\n",
    "            .from_tensor_slices( ({'input_1':input_ids[idxT,],\n",
    "                  'input_2':attention_mask[idxT,], 'input_3':token_type_ids[idxT,]},\n",
    "                 {'start_token_id':start_ids[idxT,], 'end_token_id':end_ids[idxT,]}) )\n",
    "            .shuffle(buffer_size = input_ids.shape[0])\n",
    "            .repeat(epochs)\n",
    "            .batch(BATCH_SIZE,drop_remainder=True)\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "     \n",
    "    X_val = (\n",
    "        tf.data.Dataset\n",
    "            .from_tensor_slices( ({'input_1':input_ids[idxV,],\n",
    "                  'input_2':attention_mask[idxV,], 'input_3':token_type_ids[idxV,]},\n",
    "                 {'start_token_id':start_ids[idxV,], 'end_token_id':end_ids[idxV,]}) )\n",
    "            .batch(4*BATCH_SIZE)\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "\n",
    "    X_test = (\n",
    "        tf.data.Dataset\n",
    "            .from_tensor_slices( ({'input_1':input_ids_test,\n",
    "                  'input_2':attention_mask_test, 'input_3':token_type_ids_test},\n",
    "                 ) )\n",
    "            .batch(4*BATCH_SIZE)\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "    \n",
    "    with strategy.scope():\n",
    "      model = build_model_CNN()\n",
    "        \n",
    "   \n",
    "        \n",
    "    sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"roberta-fold{}.h5\".format(fold+1), monitor='val_loss', verbose=1, save_best_only=True,\n",
    "        save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "    \n",
    "#    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    steps_per_epoch= int(np.ceil(input_ids[idxT,].shape[0]/BATCH_SIZE ))\n",
    "    validation_steps = int(np.ceil(input_ids[idxV,].shape[0]/BATCH_SIZE ))\n",
    "\n",
    "\n",
    "    model.fit(X_train, validation_data = X_val,\n",
    "              epochs=epochs, verbose=1, callbacks=[sv])\n",
    "    \n",
    "    print('Loading model...')\n",
    "    model.load_weights('roberta-fold{}.h5'.format(fold+1))\n",
    "    shutil.copy2(r'roberta-fold{}.h5'.format(fold+1), r'/content/gdrive/My Drive/')\n",
    "\n",
    "    print('Predicting out-of-fold answer span')\n",
    "    oof_start[idxV,],oof_end[idxV,] = model.predict(X_val, verbose=1)\n",
    "    # DISPLAY FOLD JACCARD\n",
    "    jac_oof = []\n",
    "    for k in idxV:\n",
    "        a = np.argmax(oof_start[k,])\n",
    "        b = np.argmax(oof_end[k,])\n",
    "        true_answer =  \" \" + \" \".join(train.loc[k,'selected_text'].split())\n",
    "        context =  \" \" + \" \".join(train.loc[k,'text'].split())\n",
    "        if (train.loc[k, 'sentiment'] == 'neutral'):\n",
    "              pred_answer = \" \" + \" \".join(train.loc[k,'text'].split())\n",
    "        elif a>b: \n",
    "            enc_question = tokenizer.encode(train.loc[k,'sentiment'])\n",
    "            enc_context = tokenizer.encode(context)\n",
    "            enc_ids = [0] + enc_question.ids + [2,2] +   enc_context.ids + [2]\n",
    "            pred_answer = tokenizer.decode(enc_ids[a:]) \n",
    "        else:\n",
    "            enc_question = tokenizer.encode(train.loc[k,'sentiment'])\n",
    "            enc_context = tokenizer.encode(context)\n",
    "            enc_ids = [0] + enc_question.ids + [2,2] +   enc_context.ids + [2]\n",
    "            pred_answer = tokenizer.decode(enc_ids[a:b+1])       \n",
    "        jac_oof.append(jaccard(pred_answer, true_answer))\n",
    "    jaccard_scores.append(np.mean(jac_oof))\n",
    "    print('FOLD %i Jaccard ='%(fold+1),np.mean(jac_oof))\n",
    "\n",
    "    print('Predicting Test answer span')\n",
    "    preds = model.predict(X_test, verbose=1)\n",
    "    preds_start += preds[0]/kfold_n_splits\n",
    "    preds_end += preds[1]/kfold_n_splits\n",
    "  return {'pred_test_start': preds_start, 'pred_test_end': preds_end,\n",
    "          'jaccard_kfold': jaccard_scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "kHUtKrPK_nwc",
    "outputId": "bed292a9-ee47-4c67-f12a-f6b79ff0f51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 6]\n",
      "[3 5 4]\n",
      "[3 5 6]\n",
      "[2 4 1]\n",
      "[5 4 3]\n",
      "[1 2 6]\n",
      "#########################\n",
      "[2 3 5]\n",
      "[4 2 4]\n",
      "[1 6 1]\n",
      "[6 3 1]\n",
      "[5 6 5]\n",
      "[4 2 3]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3,4,5,6]).shuffle(buffer_size = 5).repeat(3).batch(3)\n",
    "for element in dataset.as_numpy_iterator():\n",
    "  print(element)\n",
    "\n",
    "print('#'*25)\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3,4,5,6]).repeat(3).shuffle(buffer_size = 5).batch(3)\n",
    "for element in dataset.as_numpy_iterator():\n",
    "  print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qSd48gx-Tm8T",
    "outputId": "07240184-371a-465b-a375-2825b24bc6f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 1\n",
      "#########################\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - ETA: 0s - loss: 1.7505 - start_token_id_loss: 0.8483 - end_token_id_loss: 0.9022\n",
      "Epoch 00001: val_loss improved from inf to 1.49150, saving model to roberta-fold1.h5\n",
      "515/515 [==============================] - 106s 206ms/step - loss: 1.7505 - start_token_id_loss: 0.8483 - end_token_id_loss: 0.9022 - val_loss: 1.4915 - val_start_token_id_loss: 0.7183 - val_end_token_id_loss: 0.7732\n",
      "Epoch 2/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 1.1694 - start_token_id_loss: 0.5674 - end_token_id_loss: 0.6020\n",
      "Epoch 00002: val_loss did not improve from 1.49150\n",
      "515/515 [==============================] - 78s 152ms/step - loss: 1.1694 - start_token_id_loss: 0.5674 - end_token_id_loss: 0.6020 - val_loss: 1.7241 - val_start_token_id_loss: 0.8377 - val_end_token_id_loss: 0.8865\n",
      "Epoch 3/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.8482 - start_token_id_loss: 0.4088 - end_token_id_loss: 0.4394\n",
      "Epoch 00003: val_loss did not improve from 1.49150\n",
      "515/515 [==============================] - 78s 152ms/step - loss: 0.8482 - start_token_id_loss: 0.4088 - end_token_id_loss: 0.4394 - val_loss: 2.2023 - val_start_token_id_loss: 1.0951 - val_end_token_id_loss: 1.1072\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 13s 1s/step\n",
      "FOLD 1 Jaccard = 0.699487344273288\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 948ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 2\n",
      "#########################\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - ETA: 0s - loss: 1.6732 - start_token_id_loss: 0.8008 - end_token_id_loss: 0.8724\n",
      "Epoch 00001: val_loss improved from inf to 1.53484, saving model to roberta-fold2.h5\n",
      "515/515 [==============================] - 107s 208ms/step - loss: 1.6732 - start_token_id_loss: 0.8008 - end_token_id_loss: 0.8724 - val_loss: 1.5348 - val_start_token_id_loss: 0.7712 - val_end_token_id_loss: 0.7636\n",
      "Epoch 2/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 1.1462 - start_token_id_loss: 0.5532 - end_token_id_loss: 0.5930\n",
      "Epoch 00002: val_loss did not improve from 1.53484\n",
      "515/515 [==============================] - 79s 153ms/step - loss: 1.1462 - start_token_id_loss: 0.5532 - end_token_id_loss: 0.5930 - val_loss: 1.7742 - val_start_token_id_loss: 0.8888 - val_end_token_id_loss: 0.8854\n",
      "Epoch 3/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.7146 - start_token_id_loss: 0.3508 - end_token_id_loss: 0.3638\n",
      "Epoch 00003: val_loss did not improve from 1.53484\n",
      "515/515 [==============================] - 79s 154ms/step - loss: 0.7146 - start_token_id_loss: 0.3508 - end_token_id_loss: 0.3638 - val_loss: 2.4787 - val_start_token_id_loss: 1.2117 - val_end_token_id_loss: 1.2670\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 13s 1s/step\n",
      "FOLD 2 Jaccard = 0.7029751692065389\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 952ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 3\n",
      "#########################\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - ETA: 0s - loss: 1.7567 - start_token_id_loss: 0.8347 - end_token_id_loss: 0.9220\n",
      "Epoch 00001: val_loss improved from inf to 1.49569, saving model to roberta-fold3.h5\n",
      "515/515 [==============================] - 107s 207ms/step - loss: 1.7567 - start_token_id_loss: 0.8347 - end_token_id_loss: 0.9220 - val_loss: 1.4957 - val_start_token_id_loss: 0.7268 - val_end_token_id_loss: 0.7689\n",
      "Epoch 2/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 1.1037 - start_token_id_loss: 0.5378 - end_token_id_loss: 0.5658\n",
      "Epoch 00002: val_loss did not improve from 1.49569\n",
      "515/515 [==============================] - 79s 152ms/step - loss: 1.1037 - start_token_id_loss: 0.5378 - end_token_id_loss: 0.5658 - val_loss: 1.7677 - val_start_token_id_loss: 0.8368 - val_end_token_id_loss: 0.9309\n",
      "Epoch 3/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.6678 - start_token_id_loss: 0.3337 - end_token_id_loss: 0.3341\n",
      "Epoch 00003: val_loss did not improve from 1.49569\n",
      "515/515 [==============================] - 79s 153ms/step - loss: 0.6678 - start_token_id_loss: 0.3337 - end_token_id_loss: 0.3341 - val_loss: 2.4550 - val_start_token_id_loss: 1.1371 - val_end_token_id_loss: 1.3178\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 13s 1s/step\n",
      "FOLD 3 Jaccard = 0.7066772248078584\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 985ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 4\n",
      "#########################\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - ETA: 0s - loss: 1.6585 - start_token_id_loss: 0.8044 - end_token_id_loss: 0.8541\n",
      "Epoch 00001: val_loss improved from inf to 1.44993, saving model to roberta-fold4.h5\n",
      "515/515 [==============================] - 108s 210ms/step - loss: 1.6585 - start_token_id_loss: 0.8044 - end_token_id_loss: 0.8541 - val_loss: 1.4499 - val_start_token_id_loss: 0.6852 - val_end_token_id_loss: 0.7647\n",
      "Epoch 2/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 1.1060 - start_token_id_loss: 0.5405 - end_token_id_loss: 0.5655\n",
      "Epoch 00002: val_loss did not improve from 1.44993\n",
      "515/515 [==============================] - 79s 154ms/step - loss: 1.1060 - start_token_id_loss: 0.5405 - end_token_id_loss: 0.5655 - val_loss: 1.8501 - val_start_token_id_loss: 0.8761 - val_end_token_id_loss: 0.9740\n",
      "Epoch 3/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.6694 - start_token_id_loss: 0.3338 - end_token_id_loss: 0.3356\n",
      "Epoch 00003: val_loss did not improve from 1.44993\n",
      "515/515 [==============================] - 80s 154ms/step - loss: 0.6694 - start_token_id_loss: 0.3338 - end_token_id_loss: 0.3356 - val_loss: 2.5553 - val_start_token_id_loss: 1.1779 - val_end_token_id_loss: 1.3773\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 14s 1s/step\n",
      "FOLD 4 Jaccard = 0.7030445596924556\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 993ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 5\n",
      "#########################\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - ETA: 0s - loss: 1.6566 - start_token_id_loss: 0.8019 - end_token_id_loss: 0.8547\n",
      "Epoch 00001: val_loss improved from inf to 1.55882, saving model to roberta-fold5.h5\n",
      "515/515 [==============================] - 108s 210ms/step - loss: 1.6566 - start_token_id_loss: 0.8019 - end_token_id_loss: 0.8547 - val_loss: 1.5588 - val_start_token_id_loss: 0.7406 - val_end_token_id_loss: 0.8183\n",
      "Epoch 2/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 1.0675 - start_token_id_loss: 0.5241 - end_token_id_loss: 0.5434\n",
      "Epoch 00002: val_loss did not improve from 1.55882\n",
      "515/515 [==============================] - 79s 154ms/step - loss: 1.0675 - start_token_id_loss: 0.5241 - end_token_id_loss: 0.5434 - val_loss: 1.8613 - val_start_token_id_loss: 0.8863 - val_end_token_id_loss: 0.9750\n",
      "Epoch 3/3\n",
      "515/515 [==============================] - ETA: 0s - loss: 0.6501 - start_token_id_loss: 0.3272 - end_token_id_loss: 0.3229\n",
      "Epoch 00003: val_loss did not improve from 1.55882\n",
      "515/515 [==============================] - 80s 154ms/step - loss: 0.6501 - start_token_id_loss: 0.3272 - end_token_id_loss: 0.3229 - val_loss: 2.5567 - val_start_token_id_loss: 1.1624 - val_end_token_id_loss: 1.3942\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 13s 1s/step\n",
      "FOLD 5 Jaccard = 0.6897554558548077\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 976ms/step\n"
     ]
    }
   ],
   "source": [
    "out = train_model(input_ids, attention_mask, token_type_ids, input_ids_test,attention_mask_test,token_type_ids_test,kfold_n_splits = 5, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3ZAwmmq4TP0"
   },
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "preds_start, preds_end = out['pred_test_start'], out['pred_test_end']\n",
    "\n",
    "for i in range(input_ids_test.shape[0]):\n",
    "    a = np.argmax(preds_start[i,])\n",
    "    b = np.argmax(preds_end[i,])\n",
    "    context = \" \" + \" \".join(test.loc[i, 'text'])\n",
    "    enc_context = tokenizer.encode(context)\n",
    "    if (test.loc[i, 'sentiment'] == 'neutral'):\n",
    "        pred_answer = context\n",
    "        test.loc[i,'selected_text'] = pred_answer.strip()\n",
    "    elif a>b:\n",
    "        pred_answer = tokenizer.decode(enc_context.ids[a-4:])\n",
    "        test.loc[i,'selected_text'] = pred_answer.strip()\n",
    "\n",
    "    else:\n",
    "        pred_answer = tokenizer.decode(enc_context.ids[a-4:b+1])   \n",
    "        test.loc[i,'selected_text'] = pred_answer.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JrVQ_L1VbhSu"
   },
   "outputs": [],
   "source": [
    "def inference(input_ids, attention_mask, token_type_ids, input_ids_test,attention_mask_test,token_type_ids_test,kfold_n_splits = 5, epochs=3):\n",
    "  jaccard_scores = []\n",
    "  oof_start = np.zeros((input_ids.shape[0],max_len))\n",
    "  oof_end = np.zeros((input_ids.shape[0],max_len))\n",
    "  preds_start = np.zeros((input_ids_test.shape[0],max_len))\n",
    "  preds_end = np.zeros((input_ids_test.shape[0],max_len))\n",
    "\n",
    "  \n",
    "\n",
    "  skf = StratifiedKFold(n_splits=kfold_n_splits,shuffle=True,random_state=12345)\n",
    "  for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
    "    K.clear_session()\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    \n",
    "    print('#'*25)\n",
    "    print('### FOLD {}'.format(fold+1))\n",
    "    print('#'*25)\n",
    "\n",
    "    X_val = (\n",
    "        tf.data.Dataset\n",
    "            .from_tensor_slices( ({'input_1':input_ids[idxV,],\n",
    "                  'input_2':attention_mask[idxV,], 'input_3':token_type_ids[idxV,]},\n",
    "                 {'start_token_id':start_ids[idxV,], 'end_token_id':end_ids[idxV,]}) )\n",
    "            .batch(4*BATCH_SIZE)\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "    X_test = (\n",
    "        tf.data.Dataset\n",
    "            .from_tensor_slices( ({'input_1':input_ids_test,\n",
    "                  'input_2':attention_mask_test, 'input_3':token_type_ids_test},\n",
    "                 ) )\n",
    "            .batch(4*BATCH_SIZE)\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = build_model_CNN()\n",
    "\n",
    "    shutil.copy2(r'/content/gdrive/My Drive/roberta-fold{}.h5'.format(fold+1), r'.')\n",
    "    print('Loading model...')\n",
    "    model.load_weights('roberta-fold%i.h5'%(fold+1))\n",
    "    \n",
    "\n",
    "    print('Predicting out-of-fold answer span')\n",
    "    oof_start[idxV,],oof_end[idxV,] = model.predict(X_val, verbose=1)\n",
    "      \n",
    "    # DISPLAY FOLD JACCARD\n",
    "    jac_oof = []\n",
    "    for k in idxV:\n",
    "        a = np.argmax(oof_start[k,])\n",
    "        b = np.argmax(oof_end[k,])\n",
    "        true_answer =  \" \" + \" \".join(train.loc[k,'selected_text'].split())\n",
    "        context = \" \" + \" \".join(train.loc[k,'text'].split())\n",
    "        if (train.loc[k, 'sentiment'] == 'neutral'):\n",
    "              pred_answer = \" \" + \" \".join(train.loc[k,'text'].split())\n",
    "        elif a>b: \n",
    "            enc_question = tokenizer.encode(train.loc[k,'sentiment'])\n",
    "            enc_context = tokenizer.encode(context)\n",
    "            enc_ids = [0] + enc_question.ids + [2,2] +   enc_context.ids + [2]\n",
    "            pred_answer = tokenizer.decode(enc_ids[a:]) \n",
    "        else:\n",
    "            enc_question = tokenizer.encode(train.loc[k,'sentiment'])\n",
    "            enc_context = tokenizer.encode(context)\n",
    "            enc_ids = [0] + enc_question.ids + [2,2] +   enc_context.ids + [2]\n",
    "            pred_answer = tokenizer.decode(enc_ids[a:b+1])       \n",
    "        jac_oof.append(jaccard(pred_answer, true_answer))\n",
    "    jaccard_scores.append(np.mean(jac_oof))\n",
    "    print('FOLD %i Jaccard ='%(fold+1),np.mean(jac_oof))\n",
    "\n",
    "    print('Predicting Test answer span')\n",
    "    preds = model.predict(X_test, verbose=1)\n",
    "    preds_start += preds[0]/kfold_n_splits\n",
    "    preds_end += preds[1]/kfold_n_splits\n",
    "  return {'pred_test_start': preds_start, 'pred_test_end': preds_end,\n",
    "          'jaccard_kfold': jaccard_scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QHYUw_-gcWw5",
    "outputId": "ef5d7ddb-780e-4ed2-9fb9-6b9b1c5e3d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 1\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 13s 1s/step\n",
      "FOLD 1 Jaccard = 0.699487344273288\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 950ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 2\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 14s 1s/step\n",
      "FOLD 2 Jaccard = 0.7029751692065389\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 964ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 3\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 14s 1s/step\n",
      "FOLD 3 Jaccard = 0.7066772248078584\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 976ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 4\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 14s 1s/step\n",
      "FOLD 4 Jaccard = 0.7030445596924556\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 992ms/step\n",
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.79.241.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.79.241.82:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 5\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting out-of-fold answer span\n",
      "11/11 [==============================] - 13s 1s/step\n",
      "FOLD 5 Jaccard = 0.6897554558548077\n",
      "Predicting Test answer span\n",
      "7/7 [==============================] - 7s 964ms/step\n"
     ]
    }
   ],
   "source": [
    "out_inf = inference(input_ids, attention_mask, token_type_ids, input_ids_test,attention_mask_test,token_type_ids_test,kfold_n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BRND3bMQhfgj",
    "outputId": "5ffd8d2b-ad9f-4be9-8370-f8a456151845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7003879507669898\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(out_inf['jaccard_kfold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xUA6_Apci6Q-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Roberta_tweet_sentimentQnA_model_tpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "448410893da446ef8ad741500514f290": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed3da6ca14784961aef8ec04fc65d432",
       "IPY_MODEL_ab6b9590599542dab5acb99bf89f78f1"
      ],
      "layout": "IPY_MODEL_985851302cc743319666020683560deb"
     }
    },
    "5b657f4a11d04d2a8685c5215b1e73b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9094538dac1d44ce9bf2a93cb5754c33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "985851302cc743319666020683560deb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f221775e79f48138f76eb0144c94b70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab6b9590599542dab5acb99bf89f78f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c05b677ca1c94b88bf7658877b469394",
      "placeholder": "​",
      "style": "IPY_MODEL_5b657f4a11d04d2a8685c5215b1e73b3",
      "value": " 657M/657M [00:11&lt;00:00, 56.5MB/s]"
     }
    },
    "c05b677ca1c94b88bf7658877b469394": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed3da6ca14784961aef8ec04fc65d432": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9094538dac1d44ce9bf2a93cb5754c33",
      "max": 657434796,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f221775e79f48138f76eb0144c94b70",
      "value": 657434796
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
